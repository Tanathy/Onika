---
applyTo: '**'
---
- we work on stable diffusion Lora lokr, lycoris, loha training and finetuning application.
- User will select the model and architecture from the available options in the UI.
- You are not allowed to create any archutecture detection logic. You have to use the architecture selected by the user in the UI.
- You are not allowed to create any model selection logic. You have to use the model selected by the user in the UI.
- You are not allowed to create any logic that downloads models from external sources. All models will be pre-downloaded and available in the models/ folder. 
- You are not allowed to use os.enviro, system environments, command line arguments. If you have to install dependencies, you have to use packages.jsonc. You are not allowed to install pytorch as it's handled by run.py.
- You can find official examples in the `examples/` folder.
- You will use the examples as reference to create your code and extend the functionality of the application.
- backend api and functionality has to be in perfect sync with the frontend UI.
- Every change and settings must be reflected in the frontend UI.
- You have to follow the style of the ui.
- If you do changes to the backend api, you have to make corresponding changes to the frontend UI.
- You have to check everything if you change on the code, analyze the impact of the changes on the whole application and make sure everything is working perfectly.
- You have to be extremely professional careful while making changes to the code and you have to test everything thoroughly.
- You perfectly understand how lora, lycoris, loha training and finetuning works.
- You have to make sure that the code is optimized for performance and efficiency.
- system we are optimizing is lora, lycoris, loha training and finetuning application for stable diffusion models.
- The system must support low, mid and high end gpus including 4gb, 6gb, 8gb, 10gb, 12gb, 16gb, 24gb and higher vrams and ampere cards.
- we must support training on cpu only systems as well.
- Professionally handle memory management, vrams, and optimizations for different hardware configurations, try to get the best performance out of the system for different hardware configurations.
- hardware configurations must be detected automatically and optimizations must be applied accordingly.
- we must support the following checkpoints and models: sd1.5, sdxl, sd3.0, sd3.5, flux, flux2
- You must read and understand how the scripts in the examples/ folder are working and implement similar functionality and techniques in the main application.
- focus on modularity, readability, maintainability and extensibility of the code.
- Every settings and training related options, parameters must be available in the frontend UI and default must be in the training.json configuration file.
- config.json should contain only application related settings and not training related settings.
- LoRa, Lycoris, LoHa training and finetuning must be implemented using the best practices and techniques available in the community.
- LoRa, Lycoris, LoHa training and finetuning must be using the same keys and parameters as the trainer unet, text encoder, vae, optimizers, schedulers etc. Be most compatible with the existing training techniques and practices.