{
    "language_name": "Русский",
    "ui": {
        "sidebar": {
            "training": "Обучение",
            "console": "Консоль",
            "metadata": "Метаданные",
            "updates": "Обновления",
            "system": "Система",
            "connecting": "Подключение...",
            "language": "Язык"
        },
        "updates": {
            "title": "Обновления системы",
            "subtitle": "Держи установку Onika в актуальном состоянии",
            "check_status_default": "Проверь обновления, чтобы увидеть доступные изменения.",
            "btn_check": "Проверить обновления",
            "btn_checking": "Проверка...",
            "btn_apply": "Применить обновления",
            "btn_applying": "Применение...",
            "details_title": "Детали обновления",
            "col_file": "Путь к файлу",
            "col_status": "Статус",
            "log_title": "Журнал обновлений",
            "status_uptodate": "Система обновлена.",
            "status_failed": "Не удалось проверить обновления.",
            "status_error": "Ошибка подключения к серверу обновлений.",
            "status_found": "Найдено доступных обновлений: {count}.",
            "checked_at": "Проверено: {time}",
            "confirm_apply": "Точно хочешь применить обновления ({count})?",
            "apply_success": "Обновления успешно применены!",
            "apply_partial": "Обновления применены, но с ошибками.",
            "apply_failed": "Не удалось применить обновления.",
            "apply_error": "Ошибка при применении обновлений."
        },
        "training": {
            "title": "Обучение",
            "subtitle": "Настрой и запусти обучение LoRA/LyCORIS",
            "preset": {
                "label": "Пресет",
                "select_placeholder": "Выбери пресет...",
                "btn_load": "Загрузить",
                "btn_save": "Сохранить пресет",
                "btn_new": "Новый пресет",
                "btn_delete": "Удалить",
                "help": "Загружает пресет из <span class=\"mono\">presets/</span> и применяет его к форме. Пресеты — быстрый способ переключать профили. «Сохранить пресет» перезаписывает выбранный пресет. «Новый пресет» создаёт новый с твоим названием. «Удалить» удаляет выбранный пресет."
            },
            "tabs": {
                "model": "Модель",
                "network": "Сеть",
                "dataset": "Датасет",
                "text_encoder": "Текстовый энкодер",
                "aug": "Аугментация \u0026 кэширование",
                "learning": "Параметры обучения",
                "advanced": "Дополнительно",
                "samples": "Сэмплы",
                "metadata": "Метаданные"
            },
            "model": {
                "base_model": "Базовая модель",
                "base_model_help": "Базовая модель, на которой будет идти обучение. Если выбрать модель, максимально близкую к твоему целевому стилю, сходимость обычно будет быстрее. Убедись, что архитектура совпадает с настройками обучения (например, SDXL base для обучения SDXL). Обучение на базовой модели вроде SDXL 1.0 чаще стабильнее, чем на сильно дообученной «baked» модели.",
                "architecture": "Архитектура модели",
                "architecture_help": "Задаёт логику архитектуры (SDXL, SD1.5, Flux), нужную для загрузки весов и работы с латентами. Если архитектура не совпадает с базовой моделью, ты получишь ошибки несовпадения размеров (shape mismatch).",
                "type_sdxl": "SDXL / Pony",
                "type_sd_legacy": "SD 1.5 / 2.0",
                "type_sd3": "SD 3.0",
                "type_sd3_5": "SD 3.5",
                "type_flux1": "Flux.1",
                "type_flux2": "Flux.2",
                "btn_optimize": "Авто-оптимизация под моё железо",
                "optimize_help": "Автоматически подбирает precision, quantization и настройки памяти на основе обнаруженного объёма VRAM на твоём GPU.",
                "btn_adjust": "Автонастройка (с учётом датасета)",
                "adjust_help": "Анализирует твой датасет (количество/размеры изображений + captions) и рекомендует стабильные настройки обучения для выбранной архитектуры. Применяет изменения как пресет.",
                "quantization": "Quantization модели (Q-LoRA)",
                "quantization_none": "None (обычный fp16/bf16)",
                "quantization_8bit": "8-bit (Low VRAM)",
                "quantization_4bit": "4-bit (Extreme Low VRAM)",
                "quantization_help": "Снижает точность модели до 8-bit или 4-bit, чтобы заметно уменьшить требования к VRAM и дать возможность обучаться даже на железе с ~8GB VRAM. Учти: более низкая точность может слегка ударить по точности и требует библиотеку `bitsandbytes`.",
                "output_name": "Имя вывода",
                "output_name_placeholder": "e.g. character_lora_v1",
                "output_name_help": "Префикс имени файла для сохранённых адаптеров LoRA. Используй уникальные имена, чтобы удобно хранить версии и не перезаписать прошлые результаты.",
                "output_dir": "Папка вывода",
                "output_dir_help": "Папка, куда будут сохраняться результаты обучения. Проверь, что на диске достаточно места — иначе обучение может оборваться.",
                "save_precision": "Точность сохранения",
                "save_precision_help": "Разрядность для сохраняемых файлов модели. `float16` — стандартный баланс размера и точности, а `float32` даёт максимальную точность ценой существенно большего размера файлов.",
                "save_precision_auto": "AUTO",
                "save_precision_fp16": "float16",
                "save_precision_bf16": "bf16",
                "save_precision_fp32": "float32",
                "save_format": "Формат сохранения",
                "save_format_help": "Формат выходных файлов. `safetensors` рекомендуется из-за безопасности и скорости загрузки. `ckpt` — устаревший формат, а `diffusers` сохраняет модель в виде структуры папок.",
                "save_format_safetensors": "safetensors",
                "save_format_ckpt": "ckpt",
                "save_format_diffusers": "diffusers",
                "save_epochs": "Сохранять каждые N эпох",
                "save_epochs_help": "Частота сохранения checkpoint'ов во время обучения. Регулярные сохранения помогают восстановиться после краша и дают несколько версий, чтобы оценить overfitting.",
                "save_steps": "Сохранять каждые N шагов",
                "save_steps_placeholder": "Необязательно",
                "save_steps_help": "Альтернативная частота сохранения, привязанная к шагам, а не к эпохам.",
                "resume": "Продолжить с checkpoint",
                "resume_placeholder": "e.g. latest or path/to/checkpoint-1000",
                "resume_help": "Продолжает обучение из ранее сохранённого состояния. Учти: если при продолжении менять базовые параметры вроде learning rate или rank, обучение может стать нестабильным.",
                "save_best": "Сохранять только лучшие модели (минимальный loss)",
                "save_best_help": "Оставляет только checkpoint с самым низким зафиксированным loss, чтобы экономить место на диске. Учти: самый низкий loss не всегда означает лучшее визуальное качество.",
                "checkpoints_limit": "Лимит checkpoint'ов",
                "checkpoints_limit_placeholder": "Необязательно",
                "checkpoints_limit_help": "Максимальное число checkpoint'ов, которые нужно хранить. Старые checkpoint'ы автоматически удаляются, чтобы контролировать расход места."
            },
            "network": {
                "title": "Настройки сети",
                "type": "Тип сети",
                "type_help": "Архитектура адаптера. LoRA — индустриальный стандарт. LoHa и LoKr дают больше выразительности, но могут требовать более тонкой настройки. OFT спроектирован так, чтобы сохранять энергию гиперсферы, и особенно хорошо подходит для моделей Flux.",
                "type_lora": "LoRA",
                "type_lycoris": "LyCORIS",
                "type_loha": "LoHA",
                "type_lokr": "LoKr",
                "type_oft": "OFT (Orthogonal Finetuning)",
                "module": "Модуль сети (Network Module)",
                "module_help": "Внутренний Python-модуль, который используется адаптером. Это продвинутая настройка — обычно её лучше не трогать.",
                "dim": "Размерность сети (Network Dim / Rank)",
                "dim_help": "Ёмкость адаптера. Более высокие значения (например, 128) позволяют выучить больше деталей, но повышают риск overfitting и дают более крупные файлы. Низкие значения (например, 16) обычно лучше обобщают и дают меньшие файлы.",
                "alpha": "Alpha сети (Network Alpha)",
                "alpha_help": "Коэффициент масштабирования, который не даёт обновлениям весов быть слишком агрессивными. Частое правило: ставь Alpha примерно в половину от Network Dim для стабильности, или равным Dim для более сильного эффекта.",
                "algo": "Алгоритм LyCORIS",
                "algo_help": "Вариант алгоритма LyCORIS (актуально только для режимов LyCORIS/LoHa). Разные алгоритмы балансируют выразительность и стабильность. Если не уверен(а), начни с <span class=\"mono\">lora</span>/<span class=\"mono\">locon</span> и переключайся только когда можешь явно измерить пользу.",
                "conv_dim": "Размер conv (Conv Rank / Dim)",
                "conv_dim_help": "Необязательный conv-rank для LoCon/LyCORIS. Низкие значения дают небольшой прирост свёрточной ёмкости; высокие увеличивают VRAM и могут быстро переобучить текстуры/детали. Оставь пустым, если ты явно не используешь conv-метод.",
                "conv_alpha": "Alpha conv (Conv Alpha)",
                "conv_alpha_help": "Необязательное масштабирование (alpha) для conv-части. Низкая alpha делает conv мягче; высокая — «кусает» сильнее и может раскачивать обучение/перестреливать. Обычно <= conv dim; если conv слишком сильный — сначала снизь alpha, а потом уже dim.",
                "dora_wd": "Weight Decay для DoRA (DoRA Weight Decay)",
                "dora_wd_help": "Weight decay, который применяется именно к magnitude-векторам DoRA.",
                "network_dropout": "Dropout сети (Network Dropout)",
                "network_dropout_help": "Случайно «выбрасывает» выходы нейронов внутри адаптера, чтобы улучшить устойчивость.",
                "rank_dropout": "Dropout rank (Rank Dropout)",
                "rank_dropout_help": "Случайно отключает отдельные rank-измерения как форму регуляризации.",
                "module_dropout": "Dropout модуля (Module Dropout)",
                "module_dropout_help": "Случайно отключает целые модули во время обучения, чтобы снижать overfitting и улучшать обобщение.",
                "lora_blocks": "Блоки LoRA (LoRA Blocks)",
                "lora_blocks_help": "Позволяет нацеливаться на конкретные блоки (например, mid blocks) внутри архитектуры модели.",
                "lora_layers": "Слои LoRA (LoRA Layers)",
                "lora_layers_help": "Позволяет нацеливаться на конкретные слои (например, attention-слои) для «хирургического» fine-tuning.",
                "advanced_lora": "Доп. опции LoRA",
                "lycoris_settings": "Настройки LyCORIS",
                "args": "Аргументы сети (args)",
                "args_help": "Дополнительные аргументы для network module в виде пар key=value, разделённых запятыми. Используй это для специальных опций вроде dropout или decomposition. Неверные аргументы могут сделать обучение нестабильным."
            },
            "dataset": {
                "dataset_type": "Тип датасета",
                "dataset_type_hub": "Hugging Face Hub",
                "dataset_type_local": "Локальные файлы",
                "dataset_type_help": "Выбери источник датасета. Hugging Face Hub удобен для публикации и скачивания датасетов. «Локальные файлы» позволяют использовать файлы с твоего устройства.",
                "path": "Путь к датасету",
                "path_help": "Папка с тренировочными изображениями и соответствующими им caption-файлами (например, .txt). Качество датасета — самый критичный фактор успеха: убедись, что captions точно описывают изображения.",
                "repo_id": "ID репозитория",
                "repo_id_placeholder": "e.g. username/repo",
                "repo_id_help": "ID репозитория на Hugging Face, откуда скачивать датасет. Оставь пустым, если используешь локальные файлы.",
                "local_dir": "Локальная папка",
                "local_dir_help": "Папка на твоём устройстве, где лежат файлы датасета. Убедись, что она доступна и что формат данных правильный.",
                "image_folder": "Папка с изображениями",
                "image_folder_help": "Подпапка внутри локальной папки, где лежат изображения для обучения.",
                "annotation_file": "Файл аннотаций",
                "annotation_file_placeholder": "e.g. captions.txt",
                "annotation_file_help": "Файл с аннотациями или captions для изображений. Используется для обучения моделей, которым нужен текстовый ввод.",
                "resolution": "Разрешение",
                "resolution_help": "Целевое разрешение обучения. Более высокое разрешение сохраняет больше деталей, но требует больше VRAM. Убедись, что разрешение подходит архитектуре (например, 1024x1024 для SDXL, 512x512 для SD1.5).",
                "batch_size": "Размер batch",
                "batch_size_help": "Сколько изображений обрабатывается одновременно. Больший batch_size может ускорить обучение и сделать градиенты более плавными, но заметно увеличивает расход VRAM.",
                "max_epochs": "Макс. эпох",
                "max_epochs_help": "Общее число полных проходов по датасету. Для обучения LoRA обычно достаточно 10–20 эпох. Слишком много эпох легко приводит к overfitting и «fried» изображениям.",
                "max_steps": "Макс. шагов",
                "max_steps_help": "Необязательный жёсткий лимит на общее число шагов обучения.",
                "max_steps_placeholder": "Необязательно",
                "bucketing": "Включить bucketing по aspect ratio",
                "bucketing_help": "Автоматически группирует изображения по соотношению сторон, чтобы избежать лишнего кропа и сохранить исходную композицию данных.",
                "bucket_steps": "Шаг bucket-разрешения",
                "bucket_steps_help": "Размер сетки для размеров bucket'ов. 64 — стандарт для большинства архитектур.",
                "min_bucket": "Мин. bucket-разрешение",
                "min_bucket_help": "Минимально допустимое разрешение bucket'а. Это не даёт обучению использовать слишком маленькие или мыльные изображения.",
                "max_bucket": "Макс. bucket-разрешение",
                "max_bucket_help": "Максимально допустимое разрешение bucket'а — помогает избежать OOM на особенно больших изображениях.",
                "center_crop": "Center crop (умный 1:1)",
                "center_crop_help": "Если включено, изображения, близкие к квадрату (например, 1210x1280), будут центр-кропнуты до идеального 1:1. Рекомендуется для обучения персонажей, чтобы кадрирование было стабильным.",
                "no_upscale": "Без upscale",
                "no_upscale_help": "Запрещает апскейл маленьких изображений до размеров bucket'а, чтобы избежать лишних артефактов.",
                "dreambooth": "DreamBooth и Prior Preservation",
                "prior_preservation": "Включить Prior Preservation (Reg Images)",
                "prior_preservation_help": "Использует regularization images, чтобы модель, обучаясь на конкретном экземпляре, не «забыла» своё базовое понимание класса (например, «person»). Это важно для сохранения общего знания модели, но увеличивает время обучения.",
                "num_class_images": "Количество class images",
                "num_class_images_help": "Целевое число regularization images. Частая рекомендация — 100 изображений класса на одно instance-изображение.",
                "instance_prompt": "Instance prompt",
                "instance_prompt_help": "Комбинация уникального trigger-слова и class-слова (например, «sks person»), которая идентифицирует конкретный объект обучения.",
                "instance_prompt_placeholder": "e.g. a photo of sks person",
                "class_prompt": "Class prompt",
                "class_prompt_help": "Общее class-слово (например, «person»), по которому определяются regularization images.",
                "class_prompt_placeholder": "e.g. a photo of a person",
                "reg_dir": "Папка Reg Images",
                "reg_dir_help": "Папка с regularization images. Используется только если включён Prior Preservation.",
                "reg_dir_placeholder": "Необязательно",
                "auto_gen": "Автогенерация Reg Images",
                "auto_gen_help": "Автоматически генерирует regularization images, если их ещё нет в указанной папке.",
                "gen_settings": "Настройки генерации",
                "neg_class_prompt": "Negative class prompt",
                "neg_class_prompt_help": "Negative prompt, который используется при генерации regularization images.",
                "neg_class_prompt_placeholder": "Необязательный negative prompt",
                "guidance": "Шкала guidance (Guidance Scale)",
                "guidance_help": "CFG scale для генерации regularization images.",
                "steps": "Шаги Reg (Reg Steps)",
                "steps_help": "Количество sampling steps для генерации regularization images.",
                "scheduler": "Reg scheduler",
                "scheduler_help": "Sampler, который используется при генерации regularization images.",
                "seed": "Reg seed",
                "seed_help": "Seed для генерации regularization images. -1 = случайный.",
                "sample_warning": "Совет: если «Sample Every N Steps» и «Sample Every N Epochs» оба оставлены пустыми, Onika не будет генерировать sample images (экономит кучу времени). На слабых и средних GPU генерировать samples во время обучения обычно не рекомендуется.",
                "train_val_split": "Разделение Train/Val",
                "train_val_split_help": "Соотношение training/validation данных. Частый вариант — 80% training и 20% validation.",
                "shuffle": "Перемешивание DataLoader",
                "shuffle_help": "Перемешивает порядок изображений в каждой эпохе, чтобы модель не выучивала последовательность датасета.",
                "workers": "Workers DataLoader",
                "workers_help": "Количество CPU-потоков для загрузки и препроцессинга данных. Большие значения быстрее кормят GPU, но если переборщить — система может начать лагать.",
                "num_workers": "Количество workers",
                "num_workers_help": "Количество подпроцессов для загрузки данных. Больше workers может ускорить загрузку, но требует больше ресурсов.",
                "persistent_workers": "Persistent workers DataLoader",
                "persistent_workers_help": "Оставляет workers загрузчика данных активными между эпохами, ускоряя обучение ценой повышенного расхода RAM.",
                "pin_memory": "Закрепление памяти (Pin Memory)",
                "pin_memory_help": "Если включено, DataLoader будет копировать Tensors в CUDA pinned memory. Это может ускорить передачу данных на GPU."
            },
            "text_encoder": {
                "title": "Текстовый энкодер",
                "ti_title": "Textual Inversion (Pivotal Tuning)",
                "weighting_title": "Взвешивание captions",
                "train": "Обучать Text Encoder",
                "train_help": "Включает обучение text encoder вместе с UNet. Это может улучшить prompt adherence, но иногда снижает гибкость/редактируемость модели.",
                "clip_skip": "Clip Skip",
                "clip_skip_help": "Пропускает верхние N слоёв CLIP text encoder. Для SD1.5 обычно используют 1, а для SDXL чаще 0. Неверные значения могут ухудшить понимание промптов.",
                "train_ti": "Обучать Textual Inversion",
                "train_ti_help": "Обучает новые tokens (Textual Inversion), добавляя в словарь модели конкретные слова/понятия.",
                "ti_frac": "Доля обучения TI",
                "ti_frac_help": "Процент от общего числа эпох, в течение которых активно обучение Textual Inversion.",
                "te_frac": "Доля обучения TE",
                "te_frac_help": "Процент от общего числа эпох, в течение которых активно обучение Text Encoder.",
                "emphasis": "Emphasis по умолчанию",
                "emphasis_help": "Множитель по умолчанию для emphasized-тегов, если вес явно не указан.",
                "de_emphasis": "De-Emphasis по умолчанию",
                "de_emphasis_help": "Множитель по умолчанию для de-emphasized-тегов, если вес явно не указан.",
                "enable_weighted": "Включить weighted captions",
                "enable_weighted_help": "Разрешает weighted-синтаксис (например, \"(word:1.1)\") в captions, чтобы точно управлять важностью отдельных терминов.",
                "new_tokens": "Новых tokens на abstraction",
                "new_tokens_help": "Сколько векторов назначается каждому новому token. Больше векторов может захватить больше деталей, но такие tokens сложнее качественно обучить.",
                "token_abs": "Token abstraction",
                "token_abs_help": "Строка-заглушка (например, \"TOK\"), которая используется в captions, чтобы обозначать новый концепт.",
                "train_text_encoder": "Обучать Text Encoder",
                "train_text_encoder_help": "Обучать ли text encoder вместе с UNet. Рекомендуется, если тебе важна лучшая привязка к промпту.",
                "text_encoder_lr": "Learning rate для Text Encoder",
                "text_encoder_lr_help": "Learning rate для text encoder. Обычно он ниже, чем learning rate у UNet."
            },
            "aug": {
                "aug_title": "Аугментация изображений",
                "enable_augmentation": "Включить аугментацию",
                "enable_augmentation_help": "Включает техники data augmentation во время обучения, чтобы улучшить обобщающую способность модели.",
                "aug_mode": "Режим аугментации",
                "aug_mode_help": "Определяет, когда аугментации включаются во время обучения. <strong>Always:</strong> каждое изображение аугментируется на каждом шаге — максимум разнообразия, но может немного замедлить обучение. <strong>Per Epoch Only:</strong> новые аугментации «бросаются» один раз на эпоху и остаются одинаковыми внутри этого прохода. Стабильнее, но всё равно меняется между эпохами. <strong>Random Probability:</strong> на каждом шаге аугментация для изображения может сработать или нет — в зависимости от отдельных настроек вроде <a href=\"#\" class=\"xref-link\" data-xref=\"flip_aug_probability\" data-xref-label=\"Flip Aug Probability\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-aug\">Flip Aug Probability</a>. В большинстве случаев хватает «Always» или «Per Epoch Only».",
                "color_aug": "Сила Color Aug",
                "color_aug_help": "Насколько агрессивно «дёргать» цвета (hue, saturation, brightness) во время обучения. <strong>0.0:</strong> цвета остаются как есть — без вмешательства. <strong>0.3-0.5:</strong> мягкая вариативность, отлично подходит большинству датасетов и помогает модели не запоминать точные цвета. <strong>0.7-1.0:</strong> сильные сдвиги цвета. Может давать странные сочетания, но реально толкает обобщение. Особенно полезно для LoRA персонажей/стилей, когда тебе важно, чтобы модель «поймала» формы и концепты и не зациклилась на конкретной палитре. Выключи, если важна точная цветопередача (брендовые цвета, конкретные наряды и т. п.).",
                "flip_aug": "Вероятность Flip Aug",
                "flip_aug_help": "Шанс отзеркалить каждое изображение по горизонтали. <strong>0.5</strong> = условный бросок монетки 50/50, по сути удваивает датасет зеркальными версиями. <strong>0.0</strong> = без флипа вообще. <strong>Важно:</strong> поставь 0, если на изображениях есть: • <strong>текст или логотипы</strong> (станут наоборот) • <strong>асимметричные вещи</strong> (машины, лица с выраженной «стороной») • <strong>направленный контент</strong> (левая/правая рука, конкретные позы). Отлично работает для симметричных сюжетов: центрированные портреты, абстракция, многие аниме-персонажи. Один из лучших приёмов против overfitting на маленьких датасетах.",
                "random_flip": "Случайный Flip (Random Flip)",
                "random_flip_help": "Случайно флипает изображения по горизонтали и/или вертикали.",
                "crop_scale": "Scale для Random Crop",
                "crop_scale_help": "Минимальный уровень зума для случайного кропа. <strong>1.0:</strong> без кропа — изображения остаются в полном размере. <strong>0.8:</strong> кроп от 80% до 100%, даёт лёгкие вариации масштаба. <strong>0.5:</strong> заметнее — может приблизить до 2×, показывая модели очень разные кадрирования. Кроп учит модель работать с объектами в разных масштабах и композициях. Суперполезно, если датасет — это одни «идеально центрированные хедшоты», а ты хочешь больше гибкости в результатах. Держи 1.0, если точное кадрирование принципиально.",
                "rotation_range": "Диапазон поворота",
                "rotation_range_help": "Случайно поворачивает изображения в указанном диапазоне (в градусах).",
                "width_shift_range": "Сдвиг по ширине",
                "width_shift_range_help": "Случайно сдвигает изображения по горизонтали в указанном диапазоне (доля от общей ширины).",
                "height_shift_range": "Сдвиг по высоте",
                "height_shift_range_help": "Случайно сдвигает изображения по вертикали в указанном диапазоне (доля от общей высоты).",
                "shear_range": "Диапазон shear",
                "shear_range_help": "Случайно применяет shear-трансформации в указанном диапазоне (в градусах).",
                "zoom_range": "Диапазон zoom",
                "zoom_range_help": "Случайно приближает или отдаляет изображения в указанном диапазоне.",
                "channel_shift_range": "Сдвиг каналов",
                "channel_shift_range_help": "Случайно сдвигает цветовые каналы изображения.",
                "brightness_range": "Диапазон brightness",
                "brightness_range_help": "Случайно меняет яркость в указанном диапазоне.",
                "contrast_range": "Диапазон contrast",
                "contrast_range_help": "Случайно меняет контраст в указанном диапазоне.",
                "saturation_range": "Диапазон saturation",
                "saturation_range_help": "Случайно меняет насыщенность в указанном диапазоне.",
                "hue_range": "Диапазон hue",
                "hue_range_help": "Случайно меняет hue в указанном диапазоне.",
                "cutout_size": "Размер CutOut",
                "cutout_size_help": "Размер квадратов выреза для аугментации CutOut. Поставь 0, чтобы отключить.",
                "grid_mask_size": "Размер Grid Mask",
                "grid_mask_size_help": "Размер ячеек для аугментации Grid Mask. Поставь 0, чтобы отключить.",
                "random_eraser": "Случайное стирание (Random Eraser)",
                "random_eraser_help": "Применяет аугментацию случайного стирания (random erasing) к изображениям.",
                "mixup_alpha": "Alpha Mixup (Mixup Alpha)",
                "mixup_alpha_help": "Параметр alpha для аугментации Mixup. Поставь 0, чтобы отключить.",
                "cutmix_alpha": "Alpha CutMix (CutMix Alpha)",
                "cutmix_alpha_help": "Параметр alpha для аугментации CutMix. Поставь 0, чтобы отключить.",
                "label_smoothing": "Сглаживание меток (Label smoothing)",
                "label_smoothing_help": "Применяет label smoothing к целевым меткам во время обучения.",
                "random_crop": "Случайный Crop (Random Crop)",
                "random_crop_help": "Случайно кропает изображения до указанного целевого размера.",
                "resize": "Изменение размера (Resize)",
                "resize_help": "Меняет размер изображений до указанного целевого размера.",
                "normalize": "Нормализация (Normalize)",
                "normalize_help": "Нормализует изображения до нулевого среднего и единичной дисперсии.",
                "denormalize": "Денормализация (Denormalize)",
                "denormalize_help": "Денормализует изображения, чтобы вернуть исходные значения пикселей.",
                "caption_aug_title": "Аугментация captions",
                "shuffle": "Перемешивание captions (Shuffle Captions)",
                "shuffle_help": "Каждый раз при использовании captions перемешивает порядок тегов/слов. Это не даёт модели заучивать фиксированные шаблоны вроде «blue eyes всегда перед long hair» — вместо этого она учится, что теги могут встречаться где угодно. Идеально для booru-стиля с тегами через запятую, где порядок не важен. Используй <a href=\"#\" class=\"xref-link\" data-xref=\"keep_tokens\" data-xref-label=\"Keep Tokens\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-aug\">Keep Tokens</a>, если нужно, чтобы trigger-слово оставалось на месте. <strong>Не используй это</strong> для captions естественным языком, где порядок слов меняет смысл («woman holding cat» ≠ «cat holding woman»).",
                "keep_tokens": "Зафиксировать tokens (Keep Tokens)",
                "keep_tokens_help": "Сколько tokens в начале каждого caption считаются «священными» и не будут перемешиваться. <strong>0:</strong> перемешивается вообще всё. <strong>1:</strong> первый token (обычно trigger) всегда остаётся первым. <strong>2-3:</strong> защищает паттерны вида «trigger, character_name». Если твои captions выглядят как «mytrigger, blonde hair, blue eyes, ...», то значение 1 закрепляет «mytrigger» в начале, а остальное рандомится. Это помогает модели связать trigger ↔ концепт, не заучивая конкретный порядок тегов. Имеет смысл только когда включён <a href=\"#\" class=\"xref-link\" data-xref=\"shuffle_caption_checkbox\" data-xref-label=\"Shuffle Captions\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-aug\">Shuffle Captions</a>.",
                "dropout": "Вероятность dropout (Dropout Rate)",
                "dropout_help": "Вероятность полностью выкинуть caption у изображения (заменив его на пустоту). Когда captions пропадают, модели приходится объяснять изображение чисто по визуалу — это тренирует unconditional generation. <strong>0.0:</strong> captions всегда присутствуют. <strong>0.05-0.1:</strong> лёгкий dropout — мягко улучшает поведение при пустых/слабых промптах. <strong>0.15-0.2:</strong> агрессивнее — сильнее толкает unconditional качество. Dropout помогает CFG (classifier-free guidance) работать лучше на inference, потому что модель реально знает, как выглядит «no prompt». Но в обучении LoRA, где prompt adherence — король, слишком большой dropout может навредить. Небольшое значение (0.05) часто полезно; для очень коротких прогонов можно вообще отключить.",
                "dropout_epochs": "Dropout каждые N эпох",
                "dropout_epochs_help": "Вместо случайного dropout на каждом шаге, это отключает captions на конкретных эпохах. <strong>0:</strong> возвращается к обычному поведению <a href=\"#\" class=\"xref-link\" data-xref=\"caption_dropout_rate\" data-xref-label=\"Dropout Rate\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-aug\">Dropout Rate</a>. <strong>1:</strong> каждая эпоха идёт без captions (довольно экстремально). <strong>5:</strong> эпохи 5, 10, 15... проходят без captions. Это даёт более структурированный режим: обычно обучение нормальное, но периодически — «слепые» эпохи. Полезно для некоторых учебных программ, но на практике чаще используют случайный dropout по шагам.",
                "noise_title": "Настройки noise",
                "noise_type": "Тип Noise Offset",
                "noise_type_help": "Математический метод, который используется для расчёта noise offset. «Original» — стандартная реализация.",
                "noise_offset": "Сила Noise Offset",
                "noise_offset_help": "Добавляет смещение к шуму во время обучения — это помогает модели давать лучший динамический диапазон (глубже чёрные и ярче белые). Обычно рекомендуют 0.05–0.1.",
                "adaptive_noise": "Adaptive Noise Scale",
                "adaptive_noise_help": "Масштабирует шум на основе ошибки предсказания модели во время обучения.",
                "noise_random": "Noise Offset (random strength)",
                "noise_random_help": "Рандомит силу noise offset для каждого шага обучения.",
                "multires_iter": "Multires Noise Iter",
                "multires_iter_help": "Применяет multi-resolution noise, чтобы улучшить обучение тонких текстур и деталей.",
                "multires_discount": "Multires Noise Discount",
                "multires_discount_help": "Коэффициент скидки (discount factor), который применяется к итерациям multi-resolution noise.",
                "edm": "EDM-style обучение (SDXL)",
                "edm_help": "Использует формулировку EDM (Elucidating the Design Space of Diffusion-Based Generative Models), которая может дать более качественные результаты для моделей SDXL.",
                "caching_title": "Кэширование",
                "cache_latents": "Кэшировать latents в RAM",
                "cache_latents_help": "Предварительно вычисляет VAE latents, чтобы заметно ускорить обучение (часто 2x–3x). Если включено, все latents кэшируются и остаются в RAM на всё обучение. Это отключает часть аугментаций «в реальном времени».",
                "cache_te": "Кэшировать text embeddings",
                "cache_te_help": "Предварительно вычисляет text embeddings для ускорения обучения. Эта настройка несовместима с активным обучением Text Encoder.",
                "cache_disk": "Кэшировать latents на диск",
                "cache_disk_help": "Сохраняет заранее вычисленные latents на диск, чтобы экономить RAM. Учти: медленный диск/IO может ухудшить производительность. Эти latents переиспользуются между сессиями обучения. Если датасет изменился, старые latents нужно удалить из cache вручную.",
                "vae_batch": "Размер batch для VAE (VAE Batch Size)",
                "vae_batch_help": "Batch size, который используется для VAE-энкодинга во время кэширования. Большие значения ускоряют процесс, но требуют больше VRAM.",
                "vae_batch_placeholder": "Auto"
            },
            "learning": {
                "optimizer": "Оптимизатор",
                "optimizer_help": "Алгоритм, который реально обновляет веса по градиентам. У разных optimizers разные сильные стороны. <strong>AdamW8bit:</strong> экономичная по памяти 8-bit версия классики. Использует примерно на 50% меньше памяти под состояния оптимизатора. Частый выбор для обучения LoRA, когда VRAM впритык. Требует библиотеку bitsandbytes. <strong>AdamW:</strong> оригинал в полной точности. Самый стабильный и проверенный вариант. Выбирай, если VRAM хватает или 8-bit вариант ведёт себя проблемно. <strong>Lion / Lion8bit:</strong> более новый вариант — часто требует заметно меньший LR (в 3–10× ниже, чем AdamW). Может давать хорошие результаты при меньшей памяти, но всё ещё довольно экспериментален. <strong>DAdaptAdam:</strong> самоадаптивный optimizer. Поставь <a href=\"#\" class=\"xref-link\" data-xref=\"learning_rate\" data-xref-label=\"Learning Rate\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">Learning Rate</a> = 1.0 и дай ему самому найти «сладкую точку». <strong>Prodigy:</strong> ещё один умный адаптивный optimizer. Тоже обычно используют LR=1.0. Часто даёт отличный результат почти без ручной возни. <strong>CAME:</strong> экспериментальный, неплох по memory efficiency. <strong>Adafactor:</strong> супер-экономный по памяти, изначально делался для огромных language models. Последняя инстанция для экстремальных ограничений по VRAM. <strong>SGD:</strong> базовый градиентный спуск. Редко используют для diffusion, но он тут — если хочешь поэкспериментировать. Поведение можно тонко настроить через <a href=\"#\" class=\"xref-link\" data-xref=\"optimizer_args\" data-xref-label=\"Optimizer Args\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">Optimizer Args</a>.",
                "optimizer_adamw": "AdamW (Stable)",
                "optimizer_adamw8bit": "AdamW8bit (Memory-efficient)",
                "optimizer_lion": "Lion (Experimental)",
                "optimizer_prodigy": "Prodigy (Advanced)",
                "optimizer_dadaptation": "DAdaptAdam (Adaptive LR)",
                "optimizer_args": "Аргументы optimizer (Optimizer Args)",
                "optimizer_args_help": "Дополнительные параметры, которые напрямую передаются в твой <a href=\"#\" class=\"xref-link\" data-xref=\"optimizer\" data-xref-label=\"Optimizer\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">optimizer</a>. Формат: <code>key=value</code>, через запятую. Примеры: <strong>weight_decay=0.01</strong> — L2 регуляризация против overfitting (часто с AdamW). <strong>betas=(0.9,0.999)</strong> — коэффициенты momentum у Adam. <strong>d_coef=1.0</strong> — D-coefficient для Prodigy/DAdaptAdam. <strong>eps=1e-8</strong> — маленькое число для численной стабильности. Значения по умолчанию обычно нормальные; лезь сюда только если следуешь конкретному гайду или реально понимаешь, что делаешь.",
                "optimizer_args_placeholder": "key=value, key2=value2",
                "lr": "Learning Rate",
                "lr_help": "Базовый learning rate для обучения.",
                "learning_rate": "Learning Rate",
                "learning_rate_help": "Самая влиятельная настройка во всём прогоне обучения. Она определяет, насколько агрессивно модель двигает веса на каждом шаге. <strong>Слишком высокий</strong> (например, 1e-3 и выше) — и ты «сожжёшь» модель: жди артефакты, шум или полный коллапс. <strong>Слишком низкий</strong> (например, 1e-6 и ниже) — и обучение будет ползти или вообще никуда не сдвинется. <strong>С чего начать:</strong> - <strong>LoRA/LyCORIS:</strong> 1e-4 до 5e-4 — частая золотая середина - <strong>Full finetune:</strong> сильно ниже, примерно 1e-6 до 1e-5 - <strong>Prodigy/DAdaptAdam:</strong> просто ставь 1.0 и дай optimizer'у самому всё подобрать. «Идеальное» значение зависит от batch size, датасета и твоей системы. Большие effective batch'и (через <a href=\"#\" class=\"xref-link\" data-xref=\"grad_acc\" data-xref-label=\"Gradient Accumulation\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Gradient Accumulation</a>) обычно спокойнее переваривают более высокий learning rate.",
                "unet_lr": "UNet LR",
                "unet_lr_help": "Переопределяет learning rate только для UNet — это основной «движок» генерации изображения. Оставь пустым, чтобы использовать глобальный <a href=\"#\" class=\"xref-link\" data-xref=\"learning_rate\" data-xref-label=\"Learning Rate\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">Learning Rate</a>. Разделение rates между UNet и Text Encoder даёт точный контроль над тем, что учится быстрее. UNet отвечает за визуал (стиль, композиция, структура), так что это напрямую влияет на то, как быстро «look» твоего объекта начнёт «запекаться». Честно: одинаковый rate для обоих чаще всего работает нормально — дели только если понимаешь, зачем.",
                "unet_lr_placeholder": "Необязательно",
                "te_lr": "Text Encoder LR",
                "te_lr_help": "Learning rate именно для Text Encoder (CLIP или T5 — зависит от базовой модели). Этот компонент переводит текстовые промпты в представление, которое понимает генератор. Частая практика: ставить около <strong>1/10 до 1/2</strong> от UNet rate, или вообще отключить (поставить 0). <strong>Если обучать:</strong> помогает модели лучше узнавать новые концепты/имена и сильнее реагировать на твои стиль-специфичные промпты. <strong>Если пропустить (0):</strong> сохраняет языковое понимание базовой модели — хорошо, когда тебе важен только визуальный стиль. Для LoRA половина от <a href=\"#\" class=\"xref-link\" data-xref=\"unet_lr\" data-xref-label=\"UNet LR\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">UNet LR</a> — хороший старт.",
                "te_lr_placeholder": "Необязательно",
                "lr_scheduler": "LR Scheduler",
                "lr_scheduler_help": "Задаёт, как learning rate меняется по ходу обучения. Это реально может «сделать» или «сломать» результат. <strong>constant:</strong> LR остаётся постоянным. Просто и предсказуемо — отлично для коротких прогонов. <strong>cosine:</strong> стартует бодро и плавно затухает по косинусной кривой. Популярен, потому что активно учит в начале и мягко «шлифует» в конце. <strong>cosine_with_restarts:</strong> тот же cosine, но периодически поднимает LR обратно. Может помочь выйти из локальных минимумов. Количество рестартов задаётся через <a href=\"#\" class=\"xref-link\" data-xref=\"lr_scheduler_num_cycles\" data-xref-label=\"LR Scheduler Cycles\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">LR Scheduler Cycles</a>. <strong>linear:</strong> прямая линия от стартового LR до нуля. Просто и эффективно. <strong>polynomial:</strong> спад по степенной функции. Поведение настраивается через <a href=\"#\" class=\"xref-link\" data-xref=\"lr_scheduler_power\" data-xref-label=\"LR Scheduler Power\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">LR Scheduler Power</a>. <strong>constant_with_warmup:</strong> сначала разгоняется с нуля, потом держит постоянный LR. Хорошо сочетается с <a href=\"#\" class=\"xref-link\" data-xref=\"warmup_steps\" data-xref-label=\"Warmup Steps\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">Warmup Steps</a> для мягкого старта. Для большинства задач LoRA тебе отлично зайдёт <strong>constant</strong> или <strong>cosine</strong>.",
                "lr_scheduler_constant": "constant",
                "lr_scheduler_linear": "linear",
                "lr_scheduler_cosine": "cosine",
                "lr_scheduler_cosine_with_restarts": "cosine_with_restarts",
                "lr_scheduler_polynomial": "polynomial",
                "lr_scheduler_constant_with_warmup": "constant_with_warmup",
                "scheduler": "LR Scheduler",
                "scheduler_help": "Стратегия, по которой learning rate меняется во время обучения.",
                "warmup": "Warmup steps",
                "warmup_help": "Сколько шагов тратить на мягкий разгон learning rate от нуля до целевого значения. Это как разминка перед тренировкой — спасает от резких градиентов, пока веса ещё далеко от оптимума. <strong>0</strong> = без warmup, сразу полный LR. <strong>10–100 шагов</strong> обычно достаточно для обучения LoRA. <strong>100–500 шагов</strong> могут помочь при full finetune или больших batch'ах. Можно задавать warmup и в процентах через <a href=\"#\" class=\"xref-link\" data-xref=\"lr_warmup_ratio\" data-xref-label=\"Warmup Ratio\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">Warmup Ratio</a>. Особенно полезно при высоких learning rate или с адаптивными optimizers вроде <a href=\"#\" class=\"xref-link\" data-xref=\"optimizer\" data-xref-label=\"Optimizer\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">Prodigy or DAdaptAdam</a>.",
                "warmup_steps": "Warmup steps",
                "warmup_steps_help": "Сколько шагов тратить на мягкий разгон learning rate от нуля до целевого значения. Это как разминка перед тренировкой — спасает от резких градиентов, пока веса ещё далеко от оптимума. <strong>0</strong> = без warmup, сразу полный LR. <strong>10–100 шагов</strong> обычно достаточно для обучения LoRA. <strong>100–500 шагов</strong> могут помочь при full finetune или больших batch'ах. Можно задавать warmup и в процентах через <a href=\"#\" class=\"xref-link\" data-xref=\"lr_warmup_ratio\" data-xref-label=\"Warmup Ratio\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">Warmup Ratio</a>. Особенно полезно при высоких learning rate или с адаптивными optimizers вроде <a href=\"#\" class=\"xref-link\" data-xref=\"optimizer\" data-xref-label=\"Optimizer\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">Prodigy or DAdaptAdam</a>.",
                "warmup_ratio": "Warmup Ratio",
                "warmup_ratio_help": "Альтернатива <a href=\"#\" class=\"xref-link\" data-xref=\"warmup_steps\" data-xref-label=\"Warmup Steps\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">Warmup Steps</a>: задаёт warmup как долю от всего обучения, а не как точное число шагов. <strong>0.0</strong> = без warmup. <strong>0.05</strong> = warmup на первых 5% обучения. <strong>0.1</strong> = warmup на первых 10%. Это удобнее, чем вручную считать шаги, потому что автоматически масштабируется под длину обучения. Если заданы и warmup_ratio, и warmup_steps — используется этот параметр.",
                "cycles": "LR Cycles",
                "cycles_help": "Сколько полных циклов «вверх-вниз» выполнять при <a href=\"#\" class=\"xref-link\" data-xref=\"lr_scheduler\" data-xref-label=\"LR Scheduler\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">cosine_with_restarts</a>. Каждый цикл опускает LR до минимума, затем поднимает обратно (обычно до меньшего пика, чем раньше). <strong>1</strong> = один цикл на всё обучение — почти как обычный cosine. <strong>2–4</strong> цикла могут помочь «стряхнуть» модель из локальных минимумов и лучше исследовать ландшафт loss. Больше cycles = больше «restarts» = больше исследования, но потенциально меньше стабильности ближе к концу. Имеет смысл только если выбран cosine_with_restarts.",
                "scheduler_power": "Scheduler Power",
                "scheduler_power_help": "Показатель степени для <a href=\"#\" class=\"xref-link\" data-xref=\"lr_scheduler\" data-xref-label=\"LR Scheduler\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">polynomial scheduler</a>. Определяет, насколько агрессивно падает LR. <strong>1.0</strong> = линейный спад. <strong>> 1.0</strong> (например, 2.0) = быстро падает в начале, потом замедляется. <strong>< 1.0</strong> (например, 0.5) = медленно в начале, быстрее к концу. Работает только если выбран polynomial scheduler. Значение 1.0 по умолчанию обычно норм.",
                "total_steps": "Всего шагов (Total Steps)",
                "total_steps_help": "Общее число шагов обучения.",
                "gradient_accumulation_steps": "Шаги накопления градиента (Gradient Accumulation Steps)",
                "gradient_accumulation_steps_help": "Сколько шагов накапливать градиенты перед обновлением весов.",
                "ema_unet": "EMA для UNet (EMA for UNet)",
                "ema_unet_help": "Держит скользящее среднее весов UNet во время обучения. Вместо того чтобы брать «сырые» веса последнего шага (они могут быть шумными), EMA даёт «сглаженную» версию, которая часто выглядит лучше и надёжнее обобщает. Проще говоря: шумоподавление для весов — EMA checkpoint нередко оказывается лучше «обычного». Минус: расход VRAM на веса UNet фактически удваивается (хранится две копии). Скорость сглаживания задаётся через <a href=\"#\" class=\"xref-link\" data-xref=\"ema_decay\" data-xref-label=\"EMA Decay\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">EMA Decay</a>. Для длинных прогонов очень рекомендуется, если VRAM позволяет.",
                "ema_te": "EMA для Text Encoder (EMA for Text Encoder)",
                "ema_te_help": "То же самое, что и <a href=\"#\" class=\"xref-link\" data-xref=\"ema_unet_checkbox\" data-xref-label=\"EMA for UNet\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">UNet EMA</a>, но для text encoder. Обычно менее критично, чем UNet EMA, потому что веса text encoder при обучении LoRA часто меняются мягче. Но это всё равно добавляет расход VRAM на хранение дополнительной копии весов. Включай, если ты обучаешь text encoder и хочешь выжать максимум качества.",
                "ema_decay": "EMA Decay",
                "ema_decay_help": "Насколько EMA «помнит» старые веса по сравнению с новыми: <code>ema = decay × ema + (1-decay) × current</code>. <strong>Выше (0.999–0.9999):</strong> больше сглаживания, медленнее подхватывает изменения — хорошо для длинных прогонов. <strong>Ниже (0.99–0.995):</strong> меньше сглаживания, быстрее реагирует — лучше для коротких прогонов. <strong>0.995</strong> обычно отлично подходит для типичного обучения LoRA (сотни–пара тысяч шагов). Делаешь десятки тысяч шагов? Попробуй <strong>0.9999</strong>. Имеет смысл только если включены <a href=\"#\" class=\"xref-link\" data-xref=\"ema_unet_checkbox\" data-xref-label=\"EMA for UNet\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">EMA for UNet</a> или <a href=\"#\" class=\"xref-link\" data-xref=\"ema_text_encoder_checkbox\" data-xref-label=\"EMA for Text Encoder\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">EMA for Text Encoder</a>.",
                "mixed_precision": "Смешанная точность (Mixed Precision)",
                "mixed_precision_help": "Использовать ли mixed precision training (FP16).",
                "mixed_precision_no": "no",
                "mixed_precision_fp16": "fp16",
                "mixed_precision_bf16": "bf16",
                "fp16_opt_level": "Уровень оптимизации FP16 (FP16 Opt Level)",
                "fp16_opt_level_help": "Уровень оптимизации для обучения в FP16.",
                "loss_scale": "Масштаб loss (Loss Scale)",
                "loss_scale_help": "Коэффициент loss scaling для обучения в FP16.",
                "clip_grad": "Обрезка градиента (Clip Grad)",
                "clip_grad_help": "Обрезать ли (clip) градиенты во время обучения.",
                "log_interval": "Интервал логов (Log Interval)",
                "log_interval_help": "Интервал (в шагах), с которым логировать прогресс обучения.",
                "save_interval": "Интервал сохранения (Save Interval)",
                "save_interval_help": "Интервал (в шагах), с которым сохранять checkpoint'ы.",
                "resume_from_checkpoint": "Продолжить с checkpoint (Resume from Checkpoint)",
                "resume_from_checkpoint_help": "Продолжать ли обучение с последнего checkpoint.",
                "checkpoint_path": "Путь к checkpoint",
                "checkpoint_path_placeholder": "e.g. path/to/checkpoint",
                "checkpoint_path_help": "Путь к файлу checkpoint, с которого нужно продолжить обучение.",
                "use_8bit_adam": "Использовать 8-bit Adam",
                "use_8bit_adam_help": "Использовать ли 8-bit Adam optimizer.",
                "beta1": "Beta 1",
                "beta1_help": "Параметр beta1 для Adam optimizer.",
                "beta2": "Beta 2",
                "beta2_help": "Параметр beta2 для Adam optimizer.",
                "epsilon": "Epsilon",
                "epsilon_help": "Параметр epsilon для Adam optimizer.",
                "amsgrad": "AMSGrad",
                "amsgrad_help": "Использовать ли вариант AMSGrad для Adam optimizer.",
                "weight_decay": "Weight Decay",
                "weight_decay_help": "Weight decay (L2 penalty), который применяется к optimizer.",
                "max_grad_norm": "Max Grad Norm",
                "max_grad_norm_help": "Максимальная норма для gradient clipping.",
                "adam_beta1": "Adam Beta1",
                "adam_beta1_help": "Параметр beta1 для Adam optimizer.",
                "adam_beta2": "Adam Beta2",
                "adam_beta2_help": "Параметр beta2 для Adam optimizer.",
                "adam_epsilon": "Adam Epsilon",
                "adam_epsilon_help": "Параметр epsilon для Adam optimizer."
            },
            "advanced": {
                "attention": "Attention backend",
                "attention_help": "Какая реализация будет считать attention — самую прожорливую по памяти часть трансформеров. <strong>SDPA:</strong> встроенный оптимизированный attention в PyTorch (нужен PyTorch 2.0+). Хороший баланс скорости и памяти, без доп. установок. Рекомендуемый дефолт. <strong>xFormers:</strong> библиотека attention от Meta, часто самый быстрый вариант на NVIDIA. Может срезать VRAM на 20–40% по сравнению с обычным attention. Требует отдельной установки. <strong>None:</strong> обычный PyTorch attention — ест больше памяти, но работает везде. Используй это только если SDPA или xFormers тебе мешают. SDPA и xFormers нормально сочетаются с <a href=\"#\" class=\"xref-link\" data-xref=\"enable_aggressive_memory_saving\" data-xref-label=\"Aggressive Memory Saving\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Aggressive Memory Saving</a>.",
                "use_xformers": "Использовать xFormers",
                "use_xformers_help": "Использовать ли xFormers для более эффективного расчёта attention.",
                "xformers_memory_efficient": "Memory Efficient Attention",
                "xformers_memory_efficient_help": "Использовать ли memory-efficient attention в xFormers.",
                "gradient_checkpointing": "Gradient checkpointing",
                "gradient_checkpointing_help": "Использовать ли gradient checkpointing, чтобы экономить память.",
                "grad_acc": "Gradient accumulation",
                "grad_acc_help": "Копит градиенты несколько проходов перед обновлением весов — по сути имитирует больший batch size. <strong>effective batch = batch_size × gradient_accumulation</strong>. То есть batch_size=2 и accumulation=4 ведут себя как batch_size=8. Это спасение, когда VRAM не хватает: не влезает batch=8? Делай batch=2 и accumulation=4. Больший effective batch обычно делает обучение стабильнее, но может потребоваться подправить <a href=\"#\" class=\"xref-link\" data-xref=\"learning_rate\" data-xref-label=\"learning rate\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-basic\">learning rate</a>. Минус: всё замедляется пропорционально (accumulation 4× = примерно 4× медленнее на один effective step).",
                "mixed_precision": "Mixed precision",
                "mixed_precision_help": "Численная точность вычислений — напрямую влияет на VRAM и скорость. <strong>fp16:</strong> half precision, режет память примерно вдвое по сравнению с fp32. Хороший выбор для GTX 10-series и RTX 20-series, но на SDXL иногда может ловить NaN из-за ограниченного диапазона fp16. <strong>bf16:</strong> тоже 16 бит, но с более широким экспоненциальным диапазоном — заметно стабильнее. Используй на RTX 30-series и новее. На старом железе не работает. <strong>fp8:</strong> 8-bit точность для экстремальной экономии памяти. Экспериментально и может ухудшить качество. Требует специфичное железо. <strong>no:</strong> полный fp32. Ест ~2× VRAM, но максимально стабилен. Включай только для отладки NaN или если VRAM у тебя с запасом.",
                "mixed_precision_training": "Mixed precision training",
                "mixed_precision_training_help": "Использовать ли mixed precision training (FP16).",
                "tf32": "Разрешить TF32",
                "tf32_help": "TensorFloat-32 — режим вычислений, доступный на RTX 30-series и новее. Даёт диапазон fp32, но с меньшей точностью мантиссы (10 бит вместо 23), что может ускорять некоторые операции до 8× при почти нулевой разнице по качеству для ML. <strong>На RTX 30/40 почти всегда оставляй включённым.</strong> На старых GPU (GTX 10-series, RTX 20-series) не даёт эффекта, потому что нет нужного железа. Выключай только если подозреваешь, что TF32 почему-то портит качество (крайне редко).",
                "vae_batch": "VAE batch size",
                "vae_batch_help": "Отдельный batch size только для VAE-энкодинга — когда изображения переводятся в latent space перед тем, как их увидит UNet. Если поставить ниже основного batch size, можно сгладить пики VRAM во время энкодинга. Оставь пустым, чтобы совпадало с training batch. Поставь <strong>1</strong>, если нужна минимальная VRAM ценой скорости. Удобно, если ты ловишь OOM именно на стадии VAE encoding.",
                "vae_batch_placeholder": "Auto",
                "max_token_length": "Max token length",
                "max_token_length_help": "Максимум tokens (примерно слова/сабворды), допустимый в captions. Родной контекст CLIP — <strong>77 tokens</strong> (75 полезных + start/end). <strong>75:</strong> стандарт, почти всегда хватает. <strong>150:</strong> запас для более детальных описаний — хорошо для сложных сцен или подробных разборов персонажа. <strong>225:</strong> очень длинные, супердетальные captions. Это заметно ест VRAM и замедляет обработку. Большие лимиты работают через chunking captions. Подними до <strong>150</strong> или <strong>225</strong>, если captions регулярно превышают ~60–70 слов и обрезка выкидывает важные детали.",
                "memory_saving": "Aggressive memory saving",
                "memory_saving_help": "Врубает всё, что экономит VRAM: gradient checkpointing, CPU offloading, агрессивный garbage collection. <strong>Must-have для 4GB–8GB карт</strong> — позволяет обучать SDXL на железе, которое иначе бы задохнулось. Может снизить VRAM на 30–50% (зависит от модели). Цена: обучение становится в 2–4× медленнее из-за пересчётов и гонки данных между CPU и GPU. Отлично сочетается с хорошим <a href=\"#\" class=\"xref-link\" data-xref=\"attention_backend\" data-xref-label=\"Attention Backend\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Attention Backend</a> (SDPA или xFormers) для максимальной экономии. Есть 16GB+ VRAM? Можешь оставить выключенным и просто наслаждаться скоростью.",
                "seed": "Training seed",
                "seed_help": "Random seed для всех RNG в обучении. Выбираешь конкретный seed — получаешь <strong>reproducibility</strong>: тот же config + тот же seed = одинаковый результат (при условии одинакового железа/софта). Оставь пустым для случайной инициализации — это нормально для повседневного обучения. Полезно для A/B тестов настроек, охоты на баги или чтобы делиться воспроизводимыми конфигами. Часто выбирают запоминающиеся числа вроде <strong>42</strong>, <strong>1234</strong> или <strong>0</strong>.",
                "seed_placeholder": "Random",
                "fp16_opt_level": "FP16 Opt Level",
                "fp16_opt_level_help": "Уровень оптимизации для обучения в FP16.",
                "loss_scale": "Loss Scale",
                "loss_scale_help": "Коэффициент loss scaling для обучения в FP16.",
                "adam_beta1": "Adam Beta1",
                "adam_beta1_help": "Параметр beta1 для optimizer'а Adam.",
                "adam_beta2": "Adam Beta2",
                "adam_beta2_help": "Параметр beta2 для optimizer'а Adam.",
                "adam_epsilon": "Adam Epsilon",
                "adam_epsilon_help": "Параметр epsilon для optimizer'а Adam.",
                "amsgrad": "AMSGrad",
                "amsgrad_help": "Использовать ли вариант AMSGrad для optimizer'а Adam.",
                "weight_decay": "Weight Decay",
                "weight_decay_help": "Weight decay (L2 penalty), который применять к optimizer'у.",
                "max_grad_norm": "Max Grad Norm",
                "max_grad_norm_help": "Максимальная норма для gradient clipping.",
                "lr_scheduler": "LR Scheduler",
                "lr_scheduler_help": "Какой learning rate scheduler использовать.",
                "warmup_steps": "Warmup Steps",
                "warmup_steps_help": "Сколько шагов делать warmup для learning rate.",
                "total_steps": "Total Steps",
                "total_steps_help": "Общее число шагов обучения.",
                "gradient_accumulation_steps": "Gradient Accumulation Steps",
                "gradient_accumulation_steps_help": "Сколько шагов накапливать градиенты.",
                "clip_grad": "Clip Grad",
                "clip_grad_help": "Обрезать ли градиенты во время обучения.",
                "log_interval": "Log Interval",
                "log_interval_help": "Интервал (в шагах), с которым логировать прогресс обучения.",
                "save_interval": "Save Interval",
                "save_interval_help": "Интервал (в шагах), с которым сохранять checkpoint'ы.",
                "resume_from_checkpoint": "Resume from Checkpoint",
                "resume_from_checkpoint_help": "Продолжать ли обучение с последнего checkpoint.",
                "checkpoint_path": "Путь к checkpoint",
                "checkpoint_path_placeholder": "e.g. path/to/checkpoint",
                "checkpoint_path_help": "Путь к файлу checkpoint, с которого продолжать обучение."
            },
            "flux": {
                "title": "Настройки Flux",
                "t5xxl": "Модель T5XXL",
                "t5xxl_help": "Путь к text encoder T5XXL. Нужен для обучения Flux, чтобы обрабатывать сложные текстовые описания.",
                "ae": "Autoencoder (VAE)",
                "ae_help": "Путь к Flux Autoencoder. Отвечает за конвертацию между pixel space и latent space.",
                "clip_l": "Модель CLIP-L",
                "clip_l_help": "Путь к text encoder CLIP-L, используется вместе с T5XXL для обработки текста в Flux.",
                "max_seq_len": "Max sequence length",
                "max_seq_len_help": "Максимальная длина tokens для text encoder T5 (Flux / SD3). Больше значение — длиннее prompts/captions, но больше VRAM и медленнее обучение. Частые значения: <strong>256</strong> (default) или <strong>512</strong>.",
                "guidance_scale": "Guidance scale",
                "guidance_scale_help": "Classifier-free guidance для обучения моделей Flux и SD3. Говорит модели, насколько жёстко держаться за текстовый prompt во время обучения. <strong>3.5:</strong> рекомендованный default от Stability AI для SD3, отлично работает и для Flux. <strong>Ниже (1–2):</strong> больше креативности/вариативности, но может сильнее уходить от prompt. <strong>Выше (5–7):</strong> сильнее держится prompt, но результат может выглядеть немного «деревянным». Для SD1.5/SDXL это обычно не используют — guidance для них включается на inference.",
                "discrete_flow_shift": "Discrete flow shift",
                "discrete_flow_shift_help": "Настраивает параметр shift для flow matching. Более высокие значения могут добавить деталей, но могут потребовать больше sampling steps.",
                "model_prediction_type": "Prediction type",
                "model_prediction_type_help": "Задаёт, что именно предсказывает модель (например, raw noise или velocity). Для Flux обычно ставят \u0027raw\u0027.",
                "split_mode": "Split mode",
                "split_mode_help": "Продвинутое управление памятью для Flux. \u0027Symmetry\u0027 — стандарт; \u0027Asymmetry\u0027 может сэкономить VRAM ценой небольшой потери производительности.",
                "train_blocks": "Train blocks",
                "train_blocks_help": "Задаёт, какие блоки модели Flux обучать. \u0027all\u0027 — стандарт для полного fine-tuning.",
                "weighting_scheme": "Weighting scheme",
                "weighting_scheme_help": "Как сэмплируются timesteps во время обучения для flow-matching моделей (Flux, SD3). Это решает, каким уровням шума уделять больше внимания. <strong>None (Uniform):</strong> одинаково для всех уровней шума. Безопасный default, если не знаешь, что тебе нужно. <strong>Logit Normal:</strong> распределение «колокол», центр в <a href=\"#\" class=\"xref-link\" data-xref=\"logit_mean\" data-xref-label=\"Logit Mean\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Logit Mean</a>, ширина задаётся <a href=\"#\" class=\"xref-link\" data-xref=\"logit_std\" data-xref-label=\"Logit Std\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Logit Std</a>. Позволяет точно настроить, какие timesteps важнее всего. <strong>Mode:</strong> жёстко фокусируется на конкретном timestep, разброс контролируется <a href=\"#\" class=\"xref-link\" data-xref=\"mode_scale\" data-xref-label=\"Mode Scale\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Mode Scale</a>. Эти схемы влияют только на Flux и SD3 — для SD1.5/SDXL (epsilon-prediction) не дают эффекта.",
                "logit_mean": "Logit Mean",
                "logit_mean_help": "Где пик у logit-normal распределения при <a href=\"#\" class=\"xref-link\" data-xref=\"weighting_scheme\" data-xref-label=\"Weighting Scheme\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Logit Normal weighting</a>. <strong>0.0:</strong> центр по середине (t=0.5). <strong>Отрицательные:</strong> сдвигают фокус к более шумным timesteps (грубая структура). <strong>Положительные:</strong> сдвигают фокус к более чистым timesteps (мелкие детали). Подбирай под то, что важнее в твоём кейсе. Работает только когда Weighting Scheme = \"Logit Normal\".",
                "logit_std": "Logit Std",
                "logit_std_help": "Насколько «широкое» logit-normal распределение при <a href=\"#\" class=\"xref-link\" data-xref=\"weighting_scheme\" data-xref-label=\"Weighting Scheme\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Logit Normal weighting</a>. <strong>Ниже (0.5–0.8):</strong> узкий фокус вокруг <a href=\"#\" class=\"xref-link\" data-xref=\"logit_mean\" data-xref-label=\"Logit Mean\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Logit Mean</a> — реально «прицельно» в конкретные timesteps. <strong>Выше (1.5–2.0):</strong> распределение шире, ближе к равномерному сэмплингу. <strong>1.0:</strong> сбалансированный default. Имеет смысл только когда Weighting Scheme = \"Logit Normal\".",
                "mode_scale": "Mode Scale",
                "mode_scale_help": "Насколько «сжато» собирается mode-распределение при <a href=\"#\" class=\"xref-link\" data-xref=\"weighting_scheme\" data-xref-label=\"Weighting Scheme\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Mode weighting</a>. <strong>Ниже:</strong> samples распределяются по большему числу timesteps. <strong>Выше:</strong> samples сильнее «скучиваются» вокруг mode. <strong>1.29:</strong> значение из оригинальной статьи SD3. Оставляй так, если не экспериментируешь. Важно только когда Weighting Scheme = \"Mode\"."
            },
            "timestep": {
                "title": "Сэмплинг timesteps",
                "type": "Sampling type",
                "type_help": "Метод, которым сэмплируются timesteps во время обучения. Для Flux рекомендуют \u0027sigma_distribution\u0027.",
                "min": "Min Timestep",
                "min_help": "Минимальный timestep для сэмплинга.",
                "max": "Max Timestep",
                "max_help": "Максимальный timestep для сэмплинга.",
                "sampling_type": "Sampling type",
                "sampling_type_help": "Метод распределения шума по timesteps. \u0027sigma\u0027 — современный вариант и обычно предпочтителен для Flux/SD3.",
                "sampling_type_sigma": "sigma",
                "sampling_type_timestep": "timestep",
                "timestep_spacing": "Timestep Spacing",
                "timestep_spacing_help": "Как именно расставляются timesteps в diffusion-процессе. \u0027linspace\u0027 — стандарт.",
                "timestep_spacing_linspace": "linspace",
                "timestep_spacing_leading": "leading",
                "timestep_spacing_trailing": "trailing",
                "min_timestep": "Min Timestep",
                "min_timestep_help": "Нижняя граница сэмплинга timesteps — держит обучение в зоне более высокого шума. Timesteps идут от 0 (чистое изображение) до ~1000 (чистый шум). Если поставить что-то вроде <strong>100</strong>, модель перестанет обучаться на почти чистых изображениях. Полезно для: - фокуса на грубой структуре, когда детали не важны - тестов конкретных режимов шума - странных/специализированных расписаний обучения Оставь пустым для обычного обучения по всему диапазону. В паре с <a href=\"#\" class=\"xref-link\" data-xref=\"max_timestep\" data-xref-label=\"Max Timestep\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Max Timestep</a> можно вырезать кастомный диапазон.",
                "max_timestep": "Max Timestep",
                "max_timestep_help": "Верхняя граница сэмплинга timesteps — держит обучение подальше от самых шумных уровней. Если поставить что-то вроде <strong>800</strong>, обучение на максимальном шуме будет пропускаться. Полезно для: - полировки мелких деталей, когда грубая структура уже ок - fine-tuning с сохранением поведения базовой модели на высоком шуме - экспериментальных подходов к обучению Оставь пустым для обычного обучения по всему диапазону. В сочетании с <a href=\"#\" class=\"xref-link\" data-xref=\"min_timestep\" data-xref-label=\"Min Timestep\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Min Timestep</a> можно обучаться на любом поддиапазоне шумового расписания."
            },
            "caption": {
                "title": "Настройки captions",
                "extension": "Расширение captions",
                "extension_help": "Расширение файлов captions. Default — <strong>.txt</strong>, то есть для \"image001.png\" caption ожидается в \"image001.txt\". Можно использовать любое расширение (.caption, .captions, .tags и т.д.). Файл caption должен лежать в той же папке, что и изображение. Меняй это, если твой captioning tool пишет другое расширение.",
                "prefix": "Префикс caption",
                "prefix_help": "Текст, который добавляется в начало каждого caption во время обучения.",
                "suffix": "Суффикс caption",
                "suffix_help": "Текст, который добавляется в конец каждого caption во время обучения.",
                "dropout": "Caption dropout",
                "dropout_help": "Вероятность выкинуть весь caption во время обучения. Помогает с classifier-free guidance.",
                "token_warmup": "Token warmup",
                "token_warmup_help": "Постепенно вводит tokens из caption на начальных шагах обучения.",
                "weighted": "Weighted captions",
                "weighted_help": "Парсит веса в стиле A1111 в captions, например \"(important thing:1.3)\" или \"[less important:0.7]\". Это позволяет усиливать/ослаблять отдельные слова во время обучения. <strong>Weight > 1.0:</strong> модель уделяет этим tokens больше внимания. <strong>Weight < 1.0:</strong> модель уделяет этим tokens меньше внимания. Отлично подходит для тонкой настройки того, что в captions важнее всего. Выключай, если в captions используются обычные скобки, которые не являются весами.",
                "caption_dropout_rate": "Caption dropout rate",
                "caption_dropout_rate_help": "Вероятность выкинуть caption во время обучения. Это может помочь модели учиться генерировать без полной зависимости от captions.",
                "caption_dropout_every_n_epochs": "Caption dropout every N epochs",
                "caption_dropout_every_n_epochs_help": "Интервал (в epochs), с которым применять caption dropout.",
                "caption_tag_dropout_rate": "Caption tag dropout rate",
                "caption_tag_dropout_rate_help": "Вероятность выкинуть отдельные tags внутри caption во время обучения."
            },
            "loss": {
                "title": "Loss и оптимизация",
                "optimization_title": "Оптимизация loss",
                "loss_type": "Loss type",
                "loss_type_help": "Математическая функция, которая считает ошибку между предсказанным и истинным noise. \u0027l2\u0027 — стандарт; \u0027huber\u0027 устойчивее к выбросам.",
                "type": "Loss type",
                "type_help": "Математическая функция, которая считает разницу между предсказанным noise и target noise.",
                "loss_type_l2": "l2",
                "loss_type_l1": "l1",
                "loss_type_huber": "huber",
                "huber_delta": "Huber Delta",
                "huber_delta_help": "Порог, на котором Huber loss переключается с квадратичной части на линейную.",
                "huber_c": "Huber C",
                "huber_c_help": "Пороговый параметр для Huber loss. Чем ниже значение, тем ближе поведение к L1.",
                "huber_schedule": "Huber Schedule",
                "huber_schedule_help": "Как меняется Huber delta по ходу обучения.",
                "huber_schedule_constant": "constant",
                "huber_schedule_exponential": "exponential",
                "huber_schedule_snr": "snr",
                "min_snr_gamma": "Min-SNR Gamma",
                "min_snr_gamma_help": "Из статьи \"Efficient Diffusion Training via Min-SNR Weighting Strategy\" — исправляет проблему, когда модель переобучается на одних timesteps и игнорирует другие. Без этого качество часто получается неравномерным на разных стадиях denoising. Значение gamma (обычно <strong>5.0</strong>) задаёт порог SNR clipping. <strong>Ниже (1–3):</strong> сильнее подчёркивает high-noise timesteps (ранний denoising, грубая структура). <strong>Выше (8–20):</strong> сильнее подчёркивает low-noise timesteps (финальные детали, полировка). <strong>0:</strong> полностью выключает Min-SNR. Обычно стоит включать — заметный прирост качества почти без потери производительности.",
                "min_snr": "Min SNR Gamma",
                "min_snr_help": "Gamma для Minimum Signal-to-Noise Ratio. Помогает стабилизировать обучение, взвешивая loss в зависимости от уровней шума.",
                "ip_noise_gamma": "IP Noise Gamma",
                "ip_noise_gamma_help": "Input Perturbation Noise добавляет дополнительный случайный noise во вход во время обучения как приём регуляризации — типа dropout, но для изображений. Помогает не запоминать конкретные детали и улучшает generalization, особенно на маленьких датасетах. <strong>0.05:</strong> лёгкая регуляризация, почти не влияет на обучение. <strong>Выше 0.1:</strong> может вредить качеству из-за слишком сильного шума. Держи <strong>0</strong> для обычного обучения или чуть подними, если модель запоминает отдельные изображения вместо концептов. Независимо от <a href=\"#\" class=\"xref-link\" data-xref=\"noise_offset_input\" data-xref-label=\"Noise Offset\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Noise Offset</a> — можно использовать вместе.",
                "ip_noise": "IP Noise Gamma",
                "ip_noise_help": "Сила Input Perturbation noise. Может помочь с over-smoothing.",
                "ip_noise_gamma_random_range": "IP Noise Random Range",
                "ip_noise_gamma_random_range_help": "Диапазон случайного noise, добавляемого при IP Noise Gamma.",
                "noise_offset": "Noise Offset",
                "noise_offset_help": "Добавляет маленький постоянный offset к noise во время обучения, чтобы модель реально умела делать «настоящие» чёрные и белые вместо выцветших серых. Обычная diffusion плохо справляется с экстремально тёмными/яркими зонами, потому что noise schedule их покрывает неидеально. <strong>0.035–0.05:</strong> безопасные defaults, улучшают работу с тёмным/светлым без побочек. <strong>0.05–0.1:</strong> более агрессивный сдвиг к лучшим «краям». <strong>Выше 0.1:</strong> может дестабилизировать обучение или вызвать сдвиги цвета. Лучше всего работает вместе с <a href=\"#\" class=\"xref-link\" data-xref=\"zero_terminal_snr_checkbox\" data-xref-label=\"Zero Terminal SNR\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Zero Terminal SNR</a> — они дополняют друг друга. Особенно важно, если в датасете много тёмных сцен, ночных кадров или high-contrast изображений.",
                "v_pred": "V-Pred Like Loss",
                "v_pred_help": "Подмешивает поведение velocity-prediction в стандартное обучение noise prediction. Изначально из v-prediction моделей (SD 2.x depth/inpainting) — может сгладить обучение и уменьшить артефакты. <strong>0:</strong> чистый noise prediction (стандарт). <strong>1:</strong> полный режим velocity prediction. <strong>0.1–0.2:</strong> лёгкое влияние v-pred при сохранении совместимости с noise-pred base models. В некоторых случаях даёт более гладкие градиенты и меньше артефактов. Оставляй <strong>0</strong>, если и так всё работает или ты не уверен.",
                "scale_v_pred": "Scale V-Pred Loss",
                "zero_terminal_snr": "Zero Terminal SNR",
                "debiased": "Debiased Estimation",
                "masked": "Masked Loss (Alpha)",
                "advanced_title": "Advanced Loss Options",
                "advanced_help": "<strong>Zero Terminal SNR:</strong> подкручивает noise scheduler так, что финальный timestep становится чистым noise (SNR = 0), и это открывает генерацию «настоящего» чёрного. Обязательный напарник для <a href=\"#\" class=\"xref-link\" data-xref=\"noise_offset_input\" data-xref-label=\"Noise Offset\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Noise Offset</a> — автоматически включается при Auto. Без этого один noise offset не до конца исправляет проблемы тёмных изображений. Из статьи \"Common Diffusion Noise Schedules and Sample Steps are Flawed\".<br><strong>Debiased Estimation:</strong> исправляет bias в timestep sampling, когда часть timesteps пересэмпливается. Перевзвешивает loss так, чтобы все timesteps обучались ровнее, улучшая общее качество. Работает вместе с <a href=\"#\" class=\"xref-link\" data-xref=\"snr_gamma_input\" data-xref-label=\"Min-SNR Gamma\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">Min-SNR Gamma</a>, но решает другую проблему.<br><strong>Scale V-Pred Loss:</strong> нормализует v-prediction loss так, чтобы он совпадал по масштабу с noise-prediction. В основном полезно для v-pred base models (варианты SD 2.x) или при использовании <a href=\"#\" class=\"xref-link\" data-xref=\"v_pred_like_loss\" data-xref-label=\"V-Pred Like Loss\" data-xref-tab=\"training\" data-xref-subtab=\"cfg-advanced\">V-Pred Like Loss</a>. Для стандартных SD 1.5 или SDXL (epsilon-prediction) почти не влияет.<br><strong>Masked Loss (Alpha):</strong> использует alpha-канал PNG как training mask — модель учится только по непрозрачным пикселям. Идеально для обучения персонажей/объектов, когда фон надо игнорировать. <strong>Нужны PNG с нормальным alpha-каналом!</strong>",
                "presets": "Loss Presets",
                "presets_help": "Быстро применяет рекомендуемые настройки loss под разные цели обучения.",
                "preset_default": "Default",
                "preset_balanced": "Balanced",
                "preset_quality": "Quality",
                "preset_dark_light": "Dark/Light"
            },
            "samples": {
                "title": "Генерация сэмплов",
                "prompts_title": "Промпты для сэмплов",
                "inference_title": "Настройки инференса",
                "schedule_title": "Расписание генерации",
                "generated_title": "Сгенерированные сэмплы",
                "gallery_placeholder": "Сгенерированные сэмплы появятся здесь во время обучения...",
                "prompts": "Промпты для сэмплов",
                "prompts_help": "Введи промпты для генерации сэмплов во время обучения. Один промпт на строку.",
                "neg_prompt": "Negative prompt",
                "neg_prompt_help": "Negative prompt для генерации сэмплов.",
                "every_n_epochs": "Каждые N эпох",
                "every_n_epochs_help": "Генерировать сэмплы каждые N эпох.",
                "every_n_steps": "Каждые N шагов",
                "every_n_steps_help": "Генерировать сэмплы каждые N шагов.",
                "sampler": "Sampler",
                "sampler_help": "Sampler для генерации сэмплов.",
                "steps": "Шаги сэмплов",
                "steps_help": "Количество шагов сэмплинга для каждого изображения.",
                "inference_steps": "Inference steps",
                "inference_steps_help": "Количество шагов денойзинга для генерации сэмплов.",
                "cfg_scale": "CFG Scale",
                "cfg_scale_help": "CFG Scale для генерации сэмплов.",
                "width": "Ширина",
                "width_help": "Ширина изображения сэмпла.",
                "height": "Высота",
                "height_help": "Высота изображения сэмпла.",
                "num_images": "Изображений на промпт",
                "num_images_help": "Количество изображений для каждого промпта.",
                "seed": "Seed",
                "seed_help": "Seed для воспроизводимой генерации. -1 для случайного.",
                "format": "Формат сэмплов",
                "format_help": "Формат файлов для сохраняемых сэмплов.",
                "sample_every_n_steps": "Сэмплы каждые N шагов",
                "sample_every_n_steps_help": "Генерирует валидационные сэмплы каждые N шагов, чтобы ты видел(а) прогресс обучения. Учти: частая генерация может немного увеличить общее время обучения.",
                "sample_prompt": "Промпт сэмпла",
                "sample_prompt_help": "Промпты для валидационных изображений, чтобы оценить, насколько хорошо модель выучила концепты. Вводи по одному промпту на строку — каждый будет отрисован отдельно.",
                "sample_negative_prompt": "Negative prompt сэмпла",
                "sample_negative_prompt_help": "Negative prompt для подавления нежелательных артефактов или стилей при генерации сэмплов.",
                "sample_num_images": "Кол-во изображений",
                "sample_num_images_help": "Сколько сэмплов генерировать за один раз.",
                "sample_seed": "Seed сэмпла",
                "sample_seed_help": "Значение seed для генерации валидационных изображений.",
                "sample_width": "Ширина сэмпла",
                "sample_width_help": "Ширина сгенерированных сэмплов.",
                "sample_height": "Высота сэмпла",
                "sample_height_help": "Высота сгенерированных сэмплов.",
                "sample_guidance_scale": "Guidance scale сэмпла",
                "sample_guidance_scale_help": "Guidance scale для контроля силы промпта при генерации.",
                "sample_steps": "Шаги сэмпла",
                "sample_steps_help": "Количество шагов денойзинга для валидационных сэмплов. 20–30 шагов обычно хватает; больше — лучше качество, но дольше ждать.",
                "sample_eta": "Sample Eta",
                "sample_eta_help": "Параметр eta для контроля случайности процесса диффузии.",
                "sample_scheduler": "Sampler сэмпла",
                "sample_scheduler_help": "Sampler для генерации валидационных изображений. `Euler a` обычно рекомендуют за скорость и качество, но выбирай тот, что тебе удобнее.",
                "sample_lora": "LoRA сэмпла",
                "sample_lora_help": "Модель LoRA для генерации сэмплов.",
                "sample_lycoris": "LyCORIS сэмпла",
                "sample_lycoris_help": "Модель LyCORIS для генерации сэмплов.",
                "sample_oft": "OFT сэмпла",
                "sample_oft_help": "Модель OFT для генерации сэмплов.",
                "sample_use_8bit_adam": "Использовать 8-bit Adam для сэмплов",
                "sample_use_8bit_adam_help": "Использовать ли 8-bit Adam для генерации сэмплов.",
                "sample_fp16_opt_level": "FP16 Opt Level для сэмплов",
                "sample_fp16_opt_level_help": "Уровень оптимизации FP16 при генерации сэмплов.",
                "sample_loss_scale": "Loss Scale для сэмплов",
                "sample_loss_scale_help": "Коэффициент loss scale при генерации сэмплов.",
                "sample_adam_beta1": "Adam Beta1 для сэмплов",
                "sample_adam_beta1_help": "Параметр beta1 для Adam при генерации сэмплов.",
                "sample_adam_beta2": "Adam Beta2 для сэмплов",
                "sample_adam_beta2_help": "Параметр beta2 для Adam при генерации сэмплов.",
                "sample_adam_epsilon": "Adam Epsilon для сэмплов",
                "sample_adam_epsilon_help": "Параметр epsilon для Adam при генерации сэмплов.",
                "sample_amsgrad": "AMSGrad для сэмплов",
                "sample_amsgrad_help": "Использовать ли AMSGrad при генерации сэмплов.",
                "sample_weight_decay": "Weight Decay для сэмплов",
                "sample_weight_decay_help": "Weight decay для оптимизатора при генерации сэмплов.",
                "sample_max_grad_norm": "Max Grad Norm для сэмплов",
                "sample_max_grad_norm_help": "Максимальная норма градиента при генерации сэмплов.",
                "sample_lr_scheduler": "LR Scheduler для сэмплов",
                "sample_lr_scheduler_help": "Планировщик LR при генерации сэмплов.",
                "sample_warmup_steps": "Warmup Steps для сэмплов",
                "sample_warmup_steps_help": "Шаги прогрева LR при генерации сэмплов.",
                "sample_total_steps": "Total Steps для сэмплов",
                "sample_total_steps_help": "Общее количество шагов при генерации сэмплов.",
                "sample_gradient_accumulation_steps": "Grad Accumulation для сэмплов",
                "sample_gradient_accumulation_steps_help": "Шаги накопления градиента при генерации сэмплов.",
                "sample_clip_grad": "Clip Grad для сэмплов",
                "sample_clip_grad_help": "Обрезать ли градиенты при генерации сэмплов.",
                "sample_log_interval": "Log Interval для сэмплов",
                "sample_log_interval_help": "Интервал логирования при генерации сэмплов.",
                "sample_save_interval": "Save Interval для сэмплов",
                "sample_save_interval_help": "Интервал сохранения при генерации сэмплов.",
                "sample_resume_from_checkpoint": "Продолжить с чекпоинта для сэмплов",
                "sample_resume_from_checkpoint_help": "Продолжать ли обучение с последнего чекпоинта при генерации сэмплов.",
                "sample_checkpoint_path": "Путь к чекпоинту для сэмплов",
                "sample_checkpoint_path_placeholder": "например, path/to/checkpoint",
                "sample_checkpoint_path_help": "Путь к файлу чекпоинта для продолжения при генерации сэмплов."
            },
            "metadata": {
                "title": "Метаданные модели",
                "title_label": "Название",
                "title_help": "Публичное название LoRA.",
                "author": "Автор",
                "author_help": "Твоё имя.",
                "desc": "Описание",
                "desc_help": "Публичное описание.",
                "license": "Лицензия",
                "license_help": "Лицензия на использование.",
                "tags": "Теги",
                "tags_help": "Теги для поиска.",
                "comment": "Комментарий к обучению",
                "comment_help": "Личные заметки, сохраняемые в метаданных."
            },
            "progress": {
                "title": "Прогресс обучения",
                "status": "Статус",
                "eta": "ETA",
                "vram": "VRAM",
                "steps": "Шаги",
                "epochs": "Эпохи",
                "epoch_prefix": "Эпоха",
                "loss": "Loss",
                "loss_label": "LOSS",
                "start": "Начать обучение",
                "idle": "Система ожидает",
                "btn_stop": "Остановить обучение"
            },
            "conversion": {
                "title": "Конвертация модели",
                "subtitle": "Конвертируй модели LoRA между форматами (Diffusers \u0026harr; Kohya/LDM)",
                "card_title": "Инструмент конвертации",
                "help_text": "Используй этот инструмент для исправления проблем совместимости с AUTOMATIC1111/Forge. Он конвертирует ключи стиля «Diffusers» в стиль «Kohya/LDM» и наоборот.",
                "input_model": "Входная модель (.safetensors)",
                "btn_refresh": "Обновить",
                "model_architecture": "Архитектура модели",
                "architecture_help": "Задаёт логику архитектуры, нужную для правильного маппинга ключей. Выбор неверной архитектуры приведёт к неработоспособности модели.",
                "target_format": "Целевой формат",
                "target_format_kohya": "Kohya / LDM (для A1111, Forge, ComfyUI)",
                "output_filename": "Имя вывода (необязательно)",
                "output_filename_placeholder": "Оставь пустым для авто-имени (например, model_converted.safetensors)",
                "btn_convert": "Конвертировать модель",
                "success": "Конвертация успешна!"
            }
        },
        "console": {
            "title": "Системная консоль",
            "subtitle": "Логи обучения и системный вывод в реальном времени",
            "output_title": "Вывод консоли",
            "clear": "Очистить консоль",
            "copy": "Копировать логи",
            "auto_scroll": "Автопрокрутка",
            "wrap_lines": "Перенос строк",
            "status": "Статус",
            "step": "Шаг",
            "loss": "Loss",
            "eta": "ETA",
            "vram": "VRAM",
            "gpu_load": "Загрузка GPU",
            "cpu_load": "Загрузка CPU",
            "ram": "RAM",
            "waiting": "Ожидание начала обучения..."
        },
        "metadata_editor": {
            "title": "Редактор метаданных",
            "subtitle": "Управляй встроенными метаданными для файлов LoRA и чекпоинтов",
            "select_file": "Выбери файл",
            "select_placeholder": "Выбери файл...",
            "select_help": "Выбери модель или файл метаданных для просмотра и редактирования.",
            "btn_load": "Загрузить метаданные",
            "load_help": "Загрузить метаданные из выбранного файла для редактирования.",
            "btn_save": "Сохранить метаданные",
            "load_model": "Загрузить модель",
            "save_metadata": "Сохранить метаданные",
            "clear_fields": "Очистить поля"
        },
        "modals": {
            "save_preset_title": "Сохранить пресет",
            "save_preset_placeholder": "Введи название пресета...",
            "btn_confirm": "Подтвердить",
            "btn_cancel": "Отмена",
            "new_preset_title": "Новый пресет",
            "new_preset_placeholder": "Введи название нового пресета...",
            "preset_title": "Пресет",
            "preset_name": "Название пресета",
            "preset_placeholder": "Введи название пресета...",
            "btn_create": "Создать пресет",
            "delete_preset_title": "Удалить пресет",
            "delete_preset_confirm": "Ты точно хочешь удалить этот пресет?",
            "delete_title": "Подтверждение удаления",
            "delete_confirm": "Ты точно хочешь удалить",
            "delete_warning": "Это действие нельзя отменить. Файл будет навсегда удалён с диска.",
            "btn_delete": "Удалить",
            "stop_title": "Остановить обучение",
            "stop_confirm": "Ты точно хочешь остановить процесс обучения?",
            "stop_warning": "Весь несохранённый прогресс будет потерян. Текущий чекпоинт не будет сохранён.",
            "btn_stop": "Остановить обучение"
        },
        "notifications": {
            "success": "Успех",
            "error": "Ошибка",
            "warning": "Предупреждение",
            "info": "Информация"
        },
        "common": {
            "app_title": "Onika Trainer",
            "auto": "Авто",
            "select_placeholder": "Выбери вариант...",
            "loading": "Загрузка...",
            "searching": "Поиск...",
            "no_results": "Ничего не найдено",
            "all": "Все",
            "none": "Ничего"
        }
    }
}